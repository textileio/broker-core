// Code generated by sqlc. DO NOT EDIT.
// source: batches.sql

package db

import (
	"context"
	"time"

	"github.com/textileio/broker-core/broker"
)

const addStorageRequestInBatch = `-- name: AddStorageRequestInBatch :exec
INSERT INTO storage_requests (operation_id, storage_request_id, data_cid, batch_id, size)
VALUES ($1,$2,$3,$4,$5)
`

type AddStorageRequestInBatchParams struct {
	OperationID      string                  `json:"operationID"`
	StorageRequestID broker.StorageRequestID `json:"storageRequestID"`
	DataCid          string                  `json:"dataCid"`
	BatchID          broker.BatchID          `json:"batchID"`
	Size             int64                   `json:"size"`
}

func (q *Queries) AddStorageRequestInBatch(ctx context.Context, arg AddStorageRequestInBatchParams) error {
	_, err := q.exec(ctx, q.addStorageRequestInBatchStmt, addStorageRequestInBatch,
		arg.OperationID,
		arg.StorageRequestID,
		arg.DataCid,
		arg.BatchID,
		arg.Size,
	)
	return err
}

const createOpenBatch = `-- name: CreateOpenBatch :exec
INSERT INTO batches (batch_id,origin) values ($1,$2)
`

type CreateOpenBatchParams struct {
	BatchID broker.BatchID `json:"batchID"`
	Origin  string         `json:"origin"`
}

func (q *Queries) CreateOpenBatch(ctx context.Context, arg CreateOpenBatchParams) error {
	_, err := q.exec(ctx, q.createOpenBatchStmt, createOpenBatch, arg.BatchID, arg.Origin)
	return err
}

const doneBatchStats = `-- name: DoneBatchStats :many
SELECT origin,
       COUNT(*) as batches_count,
       (COALESCE(sum(total_size),0))::bigint as bytes
FROM batches
where status='done'
group by origin
`

type DoneBatchStatsRow struct {
	Origin       string `json:"origin"`
	BatchesCount int64  `json:"batchesCount"`
	Bytes        int64  `json:"bytes"`
}

func (q *Queries) DoneBatchStats(ctx context.Context) ([]DoneBatchStatsRow, error) {
	rows, err := q.query(ctx, q.doneBatchStatsStmt, doneBatchStats)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []DoneBatchStatsRow
	for rows.Next() {
		var i DoneBatchStatsRow
		if err := rows.Scan(&i.Origin, &i.BatchesCount, &i.Bytes); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const findOpenBatchWithSpace = `-- name: FindOpenBatchWithSpace :one
SELECT batch_id, status, total_size, origin, ready_at, created_at, updated_at
FROM batches
WHERE status='open' AND
      total_size<=$1 AND
      origin=$2
ORDER BY created_at
FOR UPDATE
LIMIT 1
`

type FindOpenBatchWithSpaceParams struct {
	TotalSize int64  `json:"totalSize"`
	Origin    string `json:"origin"`
}

func (q *Queries) FindOpenBatchWithSpace(ctx context.Context, arg FindOpenBatchWithSpaceParams) (Batch, error) {
	row := q.queryRow(ctx, q.findOpenBatchWithSpaceStmt, findOpenBatchWithSpace, arg.TotalSize, arg.Origin)
	var i Batch
	err := row.Scan(
		&i.BatchID,
		&i.Status,
		&i.TotalSize,
		&i.Origin,
		&i.ReadyAt,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getNextReadyBatch = `-- name: GetNextReadyBatch :one
UPDATE batches
SET status='executing', updated_at=CURRENT_TIMESTAMP
WHERE batch_id = (SELECT b.batch_id FROM batches b
	          WHERE b.status = 'ready'
		  ORDER BY b.ready_at asc
		  FOR UPDATE SKIP LOCKED
	          LIMIT 1)
RETURNING batch_id, total_size, origin
`

type GetNextReadyBatchRow struct {
	BatchID   broker.BatchID `json:"batchID"`
	TotalSize int64          `json:"totalSize"`
	Origin    string         `json:"origin"`
}

func (q *Queries) GetNextReadyBatch(ctx context.Context) (GetNextReadyBatchRow, error) {
	row := q.queryRow(ctx, q.getNextReadyBatchStmt, getNextReadyBatch)
	var i GetNextReadyBatchRow
	err := row.Scan(&i.BatchID, &i.TotalSize, &i.Origin)
	return i, err
}

const getStorageRequestsFromBatch = `-- name: GetStorageRequestsFromBatch :many
SELECT operation_id, storage_request_id, data_cid, batch_id, size, created_at, updated_at FROM storage_requests where batch_id=$1
`

func (q *Queries) GetStorageRequestsFromBatch(ctx context.Context, batchID broker.BatchID) ([]StorageRequest, error) {
	rows, err := q.query(ctx, q.getStorageRequestsFromBatchStmt, getStorageRequestsFromBatch, batchID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []StorageRequest
	for rows.Next() {
		var i StorageRequest
		if err := rows.Scan(
			&i.OperationID,
			&i.StorageRequestID,
			&i.DataCid,
			&i.BatchID,
			&i.Size,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const moveBatchToStatus = `-- name: MoveBatchToStatus :execrows
UPDATE batches
SET status=$2, ready_at=$3, updated_at=CURRENT_TIMESTAMP
WHERE batch_id=$1
`

type MoveBatchToStatusParams struct {
	BatchID broker.BatchID `json:"batchID"`
	Status  BatchStatus    `json:"status"`
	ReadyAt time.Time      `json:"readyAt"`
}

func (q *Queries) MoveBatchToStatus(ctx context.Context, arg MoveBatchToStatusParams) (int64, error) {
	result, err := q.exec(ctx, q.moveBatchToStatusStmt, moveBatchToStatus, arg.BatchID, arg.Status, arg.ReadyAt)
	if err != nil {
		return 0, err
	}
	return result.RowsAffected()
}

const openBatchStats = `-- name: OpenBatchStats :many
SELECT b.origin, 
       count(*) as cid_count,
       (COALESCE(sum(sr.size),0))::bigint as bytes,
       count(DISTINCT sr.batch_id) batches_count
FROM storage_requests sr
JOIN batches b ON b.batch_id=sr.batch_id
WHERE b.status='open'
group by b.origin
`

type OpenBatchStatsRow struct {
	Origin       string `json:"origin"`
	CidCount     int64  `json:"cidCount"`
	Bytes        int64  `json:"bytes"`
	BatchesCount int64  `json:"batchesCount"`
}

func (q *Queries) OpenBatchStats(ctx context.Context) ([]OpenBatchStatsRow, error) {
	rows, err := q.query(ctx, q.openBatchStatsStmt, openBatchStats)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []OpenBatchStatsRow
	for rows.Next() {
		var i OpenBatchStatsRow
		if err := rows.Scan(
			&i.Origin,
			&i.CidCount,
			&i.Bytes,
			&i.BatchesCount,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Close(); err != nil {
		return nil, err
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const updateBatchSize = `-- name: UpdateBatchSize :exec
UPDATE batches
SET total_size=$2, updated_at=CURRENT_TIMESTAMP
WHERE batch_id=$1
`

type UpdateBatchSizeParams struct {
	BatchID   broker.BatchID `json:"batchID"`
	TotalSize int64          `json:"totalSize"`
}

func (q *Queries) UpdateBatchSize(ctx context.Context, arg UpdateBatchSizeParams) error {
	_, err := q.exec(ctx, q.updateBatchSizeStmt, updateBatchSize, arg.BatchID, arg.TotalSize)
	return err
}
